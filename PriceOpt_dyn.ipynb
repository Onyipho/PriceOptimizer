{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gym\n",
        "from gym import spaces\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "orders = pd.read_csv('/content/olist_orders_dataset.csv')\n",
        "order_items = pd.read_csv('/content/olist_order_items_dataset.csv')\n",
        "products = pd.read_csv('/content/olist_products_dataset.csv')\n",
        "\n",
        "# Merge the datasets to get a complete view\n",
        "df = pd.merge(order_items, orders, on=\"order_id\")\n",
        "df = pd.merge(df, products, on=\"product_id\")\n",
        "\n",
        "# Convert order_purchase_timestamp to datetime\n",
        "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
        "\n",
        "# Feature engineering: Extracting year, month, and day from order_purchase_timestamp\n",
        "df['year'] = df['order_purchase_timestamp'].dt.year\n",
        "df['month'] = df['order_purchase_timestamp'].dt.month\n",
        "df['day'] = df['order_purchase_timestamp'].dt.day\n",
        "\n",
        "# Convert product_id and order_item_id to numerical values\n",
        "df['product_id'] = df['product_id'].astype('category').cat.codes\n",
        "df['order_item_id'] = df['order_item_id'].astype('category').cat.codes\n",
        "\n",
        "# Check for missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Select relevant features for the RL environment\n",
        "df = df[['order_id', 'product_id', 'price', 'freight_value', 'order_item_id', 'year', 'month', 'day']]\n",
        "\n",
        "# Normalize the price and freight_value columns\n",
        "df['price'] = (df['price'] - df['price'].min()) / (df['price'].max() - df['price'].min())\n",
        "df['freight_value'] = (df['freight_value'] - df['freight_value'].min()) / (df['freight_value'].max() - df['freight_value'].min())\n",
        "\n",
        "class PriceOptimizerEnv(gym.Env):\n",
        "    def __init__(self, df):\n",
        "        super(PriceOptimizerEnv, self).__init__()\n",
        "        self.df = df\n",
        "        self.current_step = 0\n",
        "        self.action_space = spaces.Discrete(10)  # 10 possible price levels\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(9,), dtype=np.float32)  # year, month, day, product_id, order_item_id, price, freight_value, stock_quantity, demand\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = 0\n",
        "        self.current_data = self.df.sample()\n",
        "        self.state = self._get_state()\n",
        "        return self.state\n",
        "\n",
        "    def _get_state(self):\n",
        "        stock_quantity = np.random.rand()\n",
        "        demand = np.random.rand()\n",
        "        state = self.current_data[['year', 'month', 'day', 'product_id', 'order_item_id', 'price', 'freight_value']].values.flatten().astype(np.float32)\n",
        "        state = np.append(state, [stock_quantity, demand])\n",
        "        return state\n",
        "\n",
        "    def step(self, action):\n",
        "        reward = self._get_reward(action)\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= len(self.df)\n",
        "        self.state = self._get_state()\n",
        "        return self.state, reward, done, {}\n",
        "\n",
        "    def _get_reward(self, action):\n",
        "        reward = np.random.rand()  # Mock reward\n",
        "        return reward\n",
        "\n",
        "# Create the environment\n",
        "env = PriceOptimizerEnv(df)\n"
      ],
      "metadata": {
        "id": "Tn7xKM1mqBoB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lptWRJVRnQyl",
        "outputId": "1efb6114-f0ae-4917-c555-fc1640128a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from /content/dqn_price_optimizer_model.h5\n"
          ]
        }
      ],
      "source": [
        "# Loading the model\n",
        "model_filename = '/content/dqn_price_optimizer_model.h5'\n",
        "loaded_model = load_model(model_filename)\n",
        "print(f\"Model loaded from {model_filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using the Model for Dynamic Pricing**"
      ],
      "metadata": {
        "id": "fwKbdevwtQCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dynamic_pricing(model, stock_quantity, demand, current_state):\n",
        "    \"\"\"\n",
        "    Use the trained model to determine the optimal price given the stock quantity and demand.\n",
        "\n",
        "    :param model: Trained DQN model\n",
        "    :param stock_quantity: Current stock quantity\n",
        "    :param demand: Current demand\n",
        "    :param current_state: Current state without stock quantity and demand\n",
        "    :return: Optimal price level (action)\n",
        "    \"\"\"\n",
        "    state = np.append(current_state, [stock_quantity, demand])\n",
        "    state = np.reshape(state, [1, env.observation_space.shape[0]])\n",
        "    action = np.argmax(model.predict(state)[0])\n",
        "    return action\n",
        "\n",
        "# Example usage\n",
        "current_state = env.reset()[:-2]  # Get the initial state without stock quantity and demand\n",
        "stock_quantity = 1  # Example stock quantity\n",
        "demand = 2  # Example demand\n",
        "optimal_price_level = dynamic_pricing(loaded_model, stock_quantity, demand, current_state)\n",
        "print(f\"Optimal Price Level: {optimal_price_level}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG2qNpm5ogby",
        "outputId": "aba57eee-7140-4c86-dd37-ab0e3a0e10bb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "Optimal Price Level: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simulating the Model with Dynamic Pricing**"
      ],
      "metadata": {
        "id": "psWcEoBMtXoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_dynamic_pricing(env, model, stock_quantities, demands, episodes=10):\n",
        "    all_rewards = []\n",
        "    all_prices = []\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        state = env.reset()[:-2]  # Get the initial state without stock quantity and demand\n",
        "        total_reward = 0\n",
        "        done = False\n",
        "        episode_prices = []\n",
        "\n",
        "        while not done:\n",
        "            stock_quantity = np.random.choice(stock_quantities)\n",
        "            demand = np.random.choice(demands)\n",
        "            action = dynamic_pricing(model, stock_quantity, demand, state)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            state = next_state[:-2]  # Update state without stock quantity and demand\n",
        "            total_reward += reward\n",
        "            episode_prices.append(action)\n",
        "\n",
        "        all_rewards.append(total_reward)\n",
        "        all_prices.append(episode_prices)\n",
        "        print(f\"Episode {episode + 1}: Total Reward: {total_reward}\")\n",
        "\n",
        "    return all_rewards, all_prices\n",
        "\n",
        "# Define possible stock quantities and demands\n",
        "stock_quantities = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "demands = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "\n",
        "# Simulate the model with dynamic pricing\n",
        "simulation_rewards, simulation_prices = simulate_dynamic_pricing(env, loaded_model, stock_quantities, demands, episodes=10)\n",
        "\n",
        "# Plot the results\n",
        "plt.plot(simulation_rewards)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Total Reward')\n",
        "plt.title('Total Rewards per Episode during Dynamic Pricing Simulation')\n",
        "plt.show()\n",
        "\n",
        "# Plot the distribution of rewards\n",
        "plt.hist(simulation_rewards, bins=10)\n",
        "plt.xlabel('Total Reward')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Total Rewards during Dynamic Pricing Simulation')\n",
        "plt.show()\n",
        "\n",
        "# Display summary statistics\n",
        "average_reward = np.mean(simulation_rewards)\n",
        "max_reward = np.max(simulation_rewards)\n",
        "min_reward = np.min(simulation_rewards)\n",
        "std_reward = np.std(simulation_rewards)\n",
        "\n",
        "print(f\"Average Reward: {average_reward}\")\n",
        "print(f\"Max Reward: {max_reward}\")\n",
        "print(f\"Min Reward: {min_reward}\")\n",
        "print(f\"Standard Deviation of Reward: {std_reward}\")\n",
        "\n",
        "# Visualize the pricing decisions\n",
        "episode_length = len(simulation_prices[0])\n",
        "average_prices = np.mean(simulation_prices, axis=0)\n",
        "\n",
        "plt.plot(range(episode_length), average_prices)\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Average Price Level')\n",
        "plt.title('Average Price Level per Step during Dynamic Pricing Simulation')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BmgL3glotl03"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}